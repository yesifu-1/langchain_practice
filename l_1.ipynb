{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f147256b-7bd2-4cd2-a18c-7cce543b7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import langchain\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage,AIMessage\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://12205-m2hl4tqk-eastus.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    openai_api_version=\"2024-08-01-preview\",\n",
    "    api_key=\"d7f27353b3b3463bb02b2708df922f35\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23ea70a9-a6ca-452c-b478-0094f94b0e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么小明的作业总是迟交？因为他总在等待灵感，但是灵感从来不会准时到达。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 39, 'total_tokens': 80, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-00226676-27f9-4a6a-aa7a-8f168541cf25-0', usage_metadata={'input_tokens': 39, 'output_tokens': 41, 'total_tokens': 80, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#消息列表\n",
    "messages = [\n",
    "    SystemMessage(content=\"用中文回复，并且字数控制在三十字以内\"),\n",
    "    HumanMessage(content=\"告诉我一个笑话\"),\n",
    "  \n",
    "]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc63b6-73b9-44c2-b51f-4f6461957d49",
   "metadata": {},
   "source": [
    "### 输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55336faf-4fa4-4d6c-a60b-e5e6ec7f8433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为什么小鸟不会玩扑克牌？因为它们都会喊：“麻雀虽小，五脏俱全！”'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 请注意，模型的响应是一个AIMessage。这包含一个字符串响应以及关于响应的其他元数据。我们通常可能只想处理字符串响应。我们可以通过使用简单的输出解析器来解析出这个响应。\n",
    "\n",
    "# 我们首先导入简单的输出解析器。\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "#使用它的一种方法是单独使用它。例如，我们可以保存语言模型调用的结果，然后将其传递给解析器。\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f1e47e-7b6a-4ac9-948e-3352250873b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为什么小鸟会掉在地上？因为它不会飞！'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更常见的是，我们可以将模型与此输出解析器“链式”连接。这意味着在此链中，每次都会调用此输出解析器。\n",
    "# 此链采用语言模型的输入类型（字符串或消息列表）并返回输出解析器的输出类型（字符串）。\n",
    "\n",
    "# 我们可以使用 | 运算符轻松创建链。| 运算符在 LangChain 中用于将两个元素组合在一起。\n",
    "chain=model|parser\n",
    "result=model.invoke(messages)\n",
    "parser.invoke(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57f7d7cf-9fef-415b-9bca-c92cae84fe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "isinstance(model,Runnable)#显然 想要使用 invoke(调用一个运行接口)这个方法 必须是一个Runnable对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38fb7e1-a175-46a5-997d-fd5938245bef",
   "metadata": {},
   "source": [
    "# 提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f56ee415-0ff5-43b0-95ff-38f0984529a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在我们直接将消息列表传递给语言模型\n",
    "#通常，它是由用户输入和应用逻辑的组合构建而成的。\n",
    "#这个应用逻辑通常会将原始用户输入转换为准备传递给语言模型的消息列表。常见的\n",
    "#转换包括添加系统消息或使用用户输入格式化模板\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e58a877d-ae88-42bb-aba3-a19dd647224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language: 要翻译成的语言\n",
    "#text: 要翻译的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e90e84f5-e051-4139-849c-732dd10cccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先，让我们创建一个字符串，我们将格式化为系统消息：\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_template = \"Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "091b7a75-f891-4ff5-92ad-334b62153431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来，我们可以创建 PromptTemplate。这将是 system_templ\n",
    "#ate 和一个更简单的模板的组合，用于放置要翻译的文本\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eeb32d01-f148-46c0-8a4b-34076bed6cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into english:', additional_kwargs={}, response_metadata={}), HumanMessage(content='what is your name', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=prompt_template.invoke({'language':'english','text':\"what is your name\"})\n",
    "#分别替代对应的占位符\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07a33a0b-772a-44da-bbcd-83383528fcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into english:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is your name', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#我们可以看到它返回一个 ChatPromptValue，由两个消息组成。如果我们想直\n",
    "#接访问这些消息，可以这样做：\n",
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0faab-091c-4029-831e-566ec2f86925",
   "metadata": {},
   "source": [
    "# 使用 LCEL 连接组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a06be124-51e3-4568-b518-f93135cd3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们现在可以使用管道 (|) 操作符将其与上面的模型和输出解析器结合起来："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3dff6c6-2970-4575-81b7-5b77733ec9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template|  model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "277faf0a-a0d8-4941-a623-739fb3613fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "#管道的链接有先后顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed2439-8bf0-4b18-ac9f-3efd375708ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7714ac-1229-4c60-9ebd-9a617a202eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
