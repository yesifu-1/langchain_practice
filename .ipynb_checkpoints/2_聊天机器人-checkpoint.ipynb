{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958c9b75-712f-481e-b9e5-5e01cca874eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import getpass\n",
    "import os\n",
    "import langchain\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "# 2. Create model\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=\"https://12205-m2hl4tqk-eastus.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-08-01-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    "    openai_api_version=\"2024-08-01-preview\",\n",
    "    api_key=\"d7f27353b3b3463bb02b2708df922f35\",  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5a5f2cc-297e-4987-a9d7-2bded49ee5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()\n",
    "chain=model|parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beebf67-9e2b-4862-b1ec-c2e602d41d19",
   "metadata": {},
   "source": [
    "### 首先直接使用模型。model是LangChain“运行接口”的实例，这意味着它们提供了一个标准接口供我们与之交互。要简单地调用模型，我们可以将消息列表传递给.invoke方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a98a6d3-292a-4f8f-8b3c-ed361c8f5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[HumanMessage(content='i am ed'),SystemMessage(content='answer word<10')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71e2dcb5-27fe-44e0-9f99-1badee4d5cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778acf58-64ec-4f85-9f61-f4bd8d997fb4",
   "metadata": {},
   "source": [
    "### 模型本身没有任何状态概念。例如，如果问一个后续问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91821be6-a570-4bcc-8475-ef2f03ac93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't know your name. Could you please tell me?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_2=[HumanMessage(content='what is my name'),SystemMessage(content='answer word<10')]\n",
    "chain.invoke(messages_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2eb2bd-4568-4aab-8eb6-3c72a63b2255",
   "metadata": {},
   "source": [
    "### 为了绕过这个问题，我们需要将整个对话历史\n",
    "### 传递给模型。让我们看看这样做会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2091e7dc-0180-47d6-aeb7-4d2a5bff58ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is jack_five.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm jack_five\"),\n",
    "        AIMessage(content=\"HI !!!\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da24b09-479f-4dce-8b9b-2891e7808bea",
   "metadata": {},
   "source": [
    "### 现在得到了好的回应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f5de5-6ad7-4b0a-a3b3-635089a77a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8deadb1f-389f-4ab7-b115-a5707f3ee7e4",
   "metadata": {},
   "source": [
    "# 消息历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc15cb-a945-4ff3-93a1-8a1b657bb2e1",
   "metadata": {},
   "source": [
    "#### 我们可以使用消息历史类来包装我们的模型，使其具有状态。 这将跟踪模型的输入和输出，并将其存储在某个数据存储中。 未来的交互将加载这些消息，并将其作为输入的一部分传递给链。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0da2ed46-ae43-4aa1-9264-93f5961a5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们可以使用消息历史类来包装我们的模型，使其具有状态。 这将跟踪模型的输入和输出，\n",
    "#并将其存储在某个数据存储中。 未来的交互将加载这些消息，并将其作为输入的一部分传递给链。\n",
    "\n",
    "#之后，我们可以导入相关类并设置我们的链，该链包装模型并添加此消息历史。这里的一个关键部分是我们作为 get_session_history 传入的函数。这个函数预计接受一个 session_id 并返回一个消息历史对象。这个 session_id 用于区分不同的对话，并应作为配置的\n",
    "#一部分在调用新链时传入（我们将展示如何做到这一点）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2010bca-0f70-471b-9b43-69b294b31a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "206c2fa3-340e-4ebf-b78e-f4a378e318ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}#用于存储会话 ID 和对应的 BaseChatMessageHistory 对象之间的映射。每个 session_id 都对应一个 BaseChatMessageHistory 实例。\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "# session_id: str：函数接收一个字符串参数 session_id，表示会话的唯一标识符。\n",
    "# -> BaseChatMessageHistory：函数的返回类型是 BaseChatMessageHistory，表示该函数将返回一个 \n",
    "# BaseChatMessageHistory 类型的对象。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f72ccd26-be4b-4408-95be-4e747d3454d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "#新的模型，拥有了对话历史函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f264b-ca6e-443d-a037-869a40d1e2c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 我们现在需要创建一个 config，每次都传递给可运行的部分。这个配置包含的信息并不是直接作为输入的一部分，但仍然是有用的。在这种情况下，我们想要包含一个 session_id。这应该看起来像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1524fccf-f4e5-4f5d-900a-000c8c06e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c850e652-5e71-412b-8bdb-9b207bc83bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
    "    config=config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b362fad0-a0b3-46ed-abba-8f41d14e5c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a37177a1-1368-4841-b7da-0d28302ec9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9c9cb-ea4d-49b7-8c16-1365397578cb",
   "metadata": {},
   "source": [
    "#### 我们的聊天机器人现在记住了关于我们的事情。如果我们更改配置以引用不同的 session_id，我们可以看到它开始新的对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc0f85bb-642b-4e09-93c4-3775110cada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, as an AI language model, I don't have access to your personal information. Please introduce yourself.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c7cbb-16b2-412b-909c-b9cd547a9b22",
   "metadata": {},
   "source": [
    "#### 这就是我们如何支持聊天机器人与多个用户进行对话的方式！现在，我们所做的只是为模型添加了一个简单的持久化层。我们可以通过添加提示词模板来使其变得更加复杂和个性化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a10f2-2c3d-4f8b-b631-42d7c8b17da3",
   "metadata": {},
   "source": [
    "#### 提示词模板帮助将原始用户信息转换为大型语言模型可以处理的格式。在这种情况下，原始用户输入只是一个消息，我们将其传递给大型语言模型。现在让我们使其变得更复杂一些。首先，让我们添加一个带有一些自定义指令的系统消息（但仍然将消息作为输入）。接下来，我们将添加除了消息之外的更多输入。首先，让我们添加一个系统消息。为此，我们将创建一个 ChatPromptTemplate。我们将利用 MessagesPlaceholder 来传递所有消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cef730ba-4803-4a99-a20d-d2ad8246e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3127745-8930-4a2e-81f1-afaf3ab8ab07",
   "metadata": {},
   "source": [
    "#### 注意，这稍微改变了输入类型 - 我们现在传递的是一个包含 messages 键的字典，其中包含一系列消息，而不是传递消息列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4700fc0a-77fb-43b7-8d3e-7c1bd820a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content='hi!i am bob')]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8444c94d-b8c1-4ac3-8162-464fee9bc6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4514c-24c4-4123-908b-1be2178446c4",
   "metadata": {},
   "source": [
    "### 我们现在可以将其包装在与之前相同的消息历史对象中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d3f2139-53e9-4b73-82c3-611a50b9f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a3c5dbe-7884-46dd-898e-116f8841d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "152b5d60-7b12-4d87-9e4d-cf7cf9a4d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Jim! How can I assist you today?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi! I'm Jim\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7398405a-9ae1-41e1-9bc6-17ef129e072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 从下面的输入可以看到，在MessagesPlaceholder(variable_name=\"messages\")\n",
    "#的位置输入多个HumanMessage，虽然先输入的HumanMessage没有应答，但也保存在了\n",
    "#store中 可以用于后续的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "594775fa-6e4e-403c-a118-57958fa47cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you\\'re looking for a great work of fiction, I would highly recommend \"The Great Gatsby\" by F. Scott Fitzgerald. The novel is set in the roaring 1920s and follows the wealthy and mysterious Jay Gatsby as he tries to win back his lost love, Daisy Buchanan. The book is a classic and is known for its beautiful prose, vivid imagery, and exploration of themes such as love, wealth, and the American Dream.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"my brother'name is wang\"),HumanMessage(content=\"introduce me a fiction book\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "897515a3-964d-4086-8a64-847e3df77f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your brother's name is Wang.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my brother'name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87c88e-2740-4a74-a979-fd62b6985e89",
   "metadata": {},
   "source": [
    "### 现在让我们使我们的提示变得更复杂一点。假设提示模板现在看起来像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea687cc6-d05a-4056-ab8a-d745658981c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "78d1ed7e-12c1-4a88-b0e4-8150ac569ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola Bob! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Spanish\"}\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f644ba2-08d9-49f4-a2e4-18e32d52b601",
   "metadata": {},
   "source": [
    "### 现在让我们将这个更复杂的链封装在一个消息历史类中。这次，由于输入中有多个键，我们需要指定正确的键来保存聊天历史。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ef9590f-d2f3-452f-8cca-5804724bc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "587623c3-dee9-4937-b2ab-745776efa6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc11\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5806c70d-9c13-4399-8700-7c8e002e806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Todd, ¿cómo puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e176821-7ebd-4264-9b59-40a02e6fd809",
   "metadata": {},
   "source": [
    "# 编写自定义令牌计数器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc2189-a81c-4c0b-9197-6c15ee311901",
   "metadata": {},
   "source": [
    "### 编写一个自定义令牌计数器函数，该函数接受消息列表并返回一个整数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b0cb081-1ec7-4099-98a5-adcdec66d7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "# pip install tiktoken\n",
    "import tiktoken\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "\n",
    "\n",
    "def str_token_counter(text: str) -> int:\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "\n",
    "def tiktoken_counter(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"Approximately reproduce https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "    For simplicity only supports str Message.contents.\n",
    "    \"\"\"\n",
    "    num_tokens = 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    tokens_per_message = 3\n",
    "    tokens_per_name = 1\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            role = \"user\"\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            role = \"assistant\"\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            role = \"tool\"\n",
    "        elif isinstance(msg, SystemMessage):\n",
    "            role = \"system\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported messages type {msg.__class__}\")\n",
    "        num_tokens += (\n",
    "            tokens_per_message\n",
    "            + str_token_counter(role)\n",
    "            + str_token_counter(msg.content)\n",
    "        )\n",
    "        if msg.name:\n",
    "            num_tokens += tokens_per_name + str_token_counter(msg.name)\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "trim_messages(\n",
    "    messages,\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=tiktoken_counter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eaa965-a22e-40ab-96dc-803514106401",
   "metadata": {},
   "source": [
    "## 管理对话历史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1a921-2764-4277-a201-3680f5567c5a",
   "metadata": {},
   "source": [
    "#### 构建聊天机器人时，一个重要的概念是如何管理对话历史。如果不加以管理，消息列表将无限增长，并可能溢出大型语言模型的上下文窗口。因此，添加一个限制您传入消息大小的步骤是很重要的。\n",
    "\n",
    "#### 我们可以通过在提示前添加一个简单的步骤，适当地修改 messages 键，然后将该新链封装在消息历史类中来实现。\n",
    "#### LangChain 提供了一些内置的助手来 管理消息列表。在这种情况下，我们将使用 trim_messages 助手来减少我们发送给模型的消息数量。修剪器允许我们指定希望保留的令牌数量，以及其他参数，例如是否希望始终保留系统消息以及是否允许部分消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5f43c8dc-e07d-4e5d-b93b-3995af803198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=60,    \n",
    "    strategy=\"last\",                #last or first   last是从后向前保留消息，会丢较前的输入\n",
    "    token_counter=tiktoken_counter, #令牌计数器\n",
    "    include_system=True,            #保留系统消息\n",
    "    allow_partial=False,            #指定是否允许部分修剪。如果设置为 True，即使无法完全满足 max_tokens 的要求，也会返回尽可能多的消息；如果设置为 F\n",
    "                                    #alse，则只有在能够完全满足 max_tokens 的情况下才会返回消息，否则返回空列表。\n",
    "    start_on=\"human\",               #指定从哪种类型的消息开始修剪\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db4e07-1e71-40b4-94d2-9fd6009db8ad",
   "metadata": {},
   "source": [
    "### 可以看到随着我们对修剪器的参数如max_tokens和strategy进行调整，输出结果将发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3110e4-6182-4ebe-b873-dcd793ad56ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
